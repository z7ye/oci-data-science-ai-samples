{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0007b9b2",
   "metadata": {},
   "source": [
    "@notebook{train-register-deploy-other-frameworks.ipynb,\n",
    "    title: Train, Register, and Deploy a Generic Model,\n",
    "    summary: Train, register, and deploy a generic model,\n",
    "    developed on: generalml_p38_cpu_v1,\n",
    "    keywords: generic model, deploy model, register model, train model,\n",
    "    license: Universal Permissive License v 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dad177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "\n",
    "!pip install -U oracle-ads catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cae905",
   "metadata": {},
   "source": [
    "<font color=gray>Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright (c) 2023 Oracle, Inc.  All rights reserved.\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.\n",
    "</font>\n",
    "\n",
    "***\n",
    "# <font color=red>Train, Register, and Deploy a Generic Model</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=teal> Oracle Cloud Infrastructure Data Science Service Team </font></p>\n",
    "\n",
    "***\n",
    "\n",
    "## Overview\n",
    "\n",
    "The notebook demonstrates how to to train, test, save and deploy an instance of the `GenericModel` class.\n",
    "\n",
    "The `GenericModel` class in Accelerated Data Science (ADS) allows you to rapidly get a model into production. The `.prepare()` method creates the model artifacts that are needed to deploy a functioning model without you having to configure it or write code, including the ability to customize the `score.py` file as needed. The model can be subsequently verified, saved, and deployed.\n",
    "\n",
    "Compatible conda pack: [General Machine Learning](https://docs.oracle.com/en-us/iaas/data-science/using/conda-gml-fam.htm) for CPU on Python 3.8 (version 1.0)\n",
    "\n",
    "### Prequisites\n",
    "\n",
    "This notebook requires authorization to work with the OCI Data Science Service. Details can be found [here](https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html#). For the purposes of this notebook what is important to to know is that resource principals will be used absent api_key authentication.\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "* <a href='#intro'>Introduction</a>\n",
    "* <a href='#create'>Create a Generic Model</a>\n",
    "* <a href='#serialize'>Generic Framework Serialization</a>\n",
    "    * <a href='#serialize_genericmodel'>Create a GenericModel</a>\n",
    "    * <a href='#serialize_prepare'>Prepare</a>\n",
    "    * <a href='#serialize_verify'>Verify</a>\n",
    "    * <a href='#serialize_save'>Save</a>\n",
    "    * <a href='#serialize_deploy'>Deploy</a>\n",
    "    * <a href='#serialize_predict'>Predict</a>\n",
    "* <a href='#clean_up'>Clean Up</a>\n",
    "* <a href='#ref'>References</a>    \n",
    "\n",
    "---\n",
    "\n",
    "Datasets are provided as a convenience. Datasets are considered third-party content and are not considered materials under your agreement with Oracle.\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.model.generic_model import GenericModel\n",
    "from numpy import array\n",
    "from numpy import ndarray\n",
    "from shutil import rmtree\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s:%(message)s\", level=logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e10be5",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "In this notebook, you will train a catboost model on a generated fake dataset. It is used to demonstrate how to use the `GenericModel` class to register a model which is not supported by exisitng frameworks.\n",
    "\n",
    "The `.prepare()` method will store the model as a pickle file. It will also generate a generic `score.py` file that will load the pickle file and call the `predict()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3738f92",
   "metadata": {},
   "source": [
    "### Authenticate\n",
    "\n",
    "Authentication to the OCI Data Science service is required. Here we default to resource principals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.set_auth(auth=\"resource_principal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405c774",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "# Create a CatBoost Model\n",
    "\n",
    "The next cell shows a toy example using catboost model trained on a fake generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0bcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import catboost\n",
    "\n",
    "seed = 42\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=15, n_classes=2, flip_y=0.05)\n",
    "trainx, testx, trainy, testy = train_test_split(X, y, test_size=30, random_state=seed)\n",
    "model = catboost.CatBoostClassifier(\n",
    "        n_estimators=100, learning_rate=0.01, random_state=42,\n",
    "    )\n",
    "model.fit(\n",
    "        trainx,\n",
    "        trainy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c0344",
   "metadata": {},
   "source": [
    "You then use the .predict() method to make predictions on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dae833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(testx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dba7b3",
   "metadata": {},
   "source": [
    "<a id='serialize'></a>\n",
    "# Generic Framework Serialization\n",
    "\n",
    "<a id='serialize_genericmodel'></a>\n",
    "## Create a GenericModel\n",
    "\n",
    "The next cell creates a model artifact directory. This directory is used to store the artifacts that are needed to deploy the model. It also creates the `GenericModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28834c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir = tempfile.mkdtemp()\n",
    "print(f\"Model artifact director: {artifact_dir}\")\n",
    "generic_model = GenericModel(estimator=model, artifact_dir=artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e25a7aa",
   "metadata": {},
   "source": [
    "The `.summary_status()` method shows the progress toward deploying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04685adb",
   "metadata": {},
   "source": [
    "<a id='serialize_prepare'></a>\n",
    "## Prepare\n",
    "\n",
    "The prepare step is performed by the `.prepare()` method of the `GenericModel` class. It creates a number of customized files that are used to run the model once it is deployed. These include:\n",
    "\n",
    "* `input_schema.json`: A JSON file that defines the nature of the features of the `X_sample` data.\n",
    "* `output_schema.json`: A JSON file that defines the nature of the dependent variable in the `y_sample` data.\n",
    "* `runtime.yaml`: This file contains information that is needed to set up the runtime environment on the deployment server.\n",
    "* `score.py`: This script contains the `load_model()` and `predict()` functions. The `load_model()` function understands the format the model file was saved in, and loads it into memory. The `.predict()` method is used to make inferences in a deployed model.\n",
    "\n",
    "The `.prepare()` method requires the `model_file_name` parameter to define the name of the model file. By default, the model is stored in a pickle file. `as_onnx` provides an alternate way to save it in the ONNX format.\n",
    "\n",
    "To create the model artifacts, you use the `.prepare()` method\n",
    "\n",
    "* `conda_env` variable defines the slug of the conda environment that was used to train the model\n",
    "\n",
    " Note that you can only pass in slug for service conda environment. For custom conda environment, you have to pass in the full path along with the `inference_python_version`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33acfb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_env = \"dataexpl_p37_cpu_v3\"\n",
    "\n",
    "generic_model.prepare(\n",
    "    inference_conda_env=conda_env,\n",
    "    training_conda_env=conda_env,\n",
    "    use_case_type=UseCaseType.MULTINOMIAL_CLASSIFICATION,\n",
    "    X_sample=testx,\n",
    "    y_sample=testy,\n",
    "    force_overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd8e43",
   "metadata": {},
   "source": [
    "The next cell uses the `.summary_status()` method to show you that the prepare step finished, and what tasks were completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8923c96",
   "metadata": {},
   "source": [
    "The `.prepare()` method has created the following fully files. However, you can modify them to fit your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca0edd",
   "metadata": {},
   "source": [
    "Once the artifacts have been created, there are a number of attributes in the `GenericModel` object that provide metadata about the model. The `.runtime` attribute details the model deployment settings and model provenance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.runtime_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3421d3",
   "metadata": {},
   "source": [
    "The `.schema_input` attribute provides metadata on the features that were used to train the model. You can use this information to determine what data must be provided to make model inferences. Each feature in the model has a section that defines the dtype, feature type, name, and if it is required. The metadata also includes the summary statistics associated with the feature type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.schema_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929d5fa",
   "metadata": {},
   "source": [
    "The `.metadata_custom` attribute provides custom metadata that contains information on the category of the metadata, description, key, and value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.metadata_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ecae0",
   "metadata": {},
   "source": [
    "The `.metadata_provenance` contains information about the code and training data that was used to create the model. This information is most useful when a Git repository is being used to manage the code for training the model. This is considered a best practice because it allows you to do things like reproduce a model, perform forensic on the model, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.metadata_provenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6446443",
   "metadata": {},
   "source": [
    "The `.metadata_taxonomy` is a key-value store that has information about the classification or taxonomy of the model. This can include information such as the model framework, use case type, hyperparameters, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35098cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.metadata_taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1032ed",
   "metadata": {},
   "source": [
    "<a id='serialize_verify'></a>\n",
    "## Verify\n",
    "\n",
    "If you modify the `score.py` file that is part of the model artifacts, then you should verify it. The verify step allows you to test those changes without having to deploy the model. The `.verify()` method takes a set of test parameters and performs the prediction by calling the `predict` function in `score.py`. It also runs the `load_model` function.\n",
    "\n",
    "**Note**: You need to make sure that data passed in to verify is json serializable as data serialization and deserialization is not supported for GenericModel class. However, other frameworks such as `SklearnModel` supports data serialization and deserialization for certain data types such as `Pandas DataFrame`, hence you can directly pass into `Pandas DataFrame` for `SklearnModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53883c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.verify(testx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845ba35",
   "metadata": {},
   "source": [
    "Update the `.summary_status()` method to show that the verify step has been completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2ab64",
   "metadata": {},
   "source": [
    "<a id='serialize_save'></a>\n",
    "## Save\n",
    "\n",
    "Once you are satisfied with the performance of the model and have verified that the `score.py` file is working, you save the model to the model catalog using the `.save()` method on the model instance. This step requires authentication provided here. The result is the model OCID which you can view in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f53bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = generic_model.save(display_name=\"Demo GenericModel model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e8c352",
   "metadata": {},
   "source": [
    "<a id='serialize_deploy'></a>\n",
    "## Deploy\n",
    "\n",
    "When the model is in the model catalog, you can use the `.deploy()` method of a `GenericModel` object to deploy the model. This method allows you to specify the attributes of the deployment such as the display name, description, instance type and count, the maximum bandwidth, and logging groups. The next cell deploys the model with the default settings, except for the custom display name. The `.deploy()` method returns a `ModelDeployment` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df515ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy = generic_model.deploy(display_name=\"Demo GenericModel deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700e286",
   "metadata": {},
   "source": [
    "After deployment, the `.summary_status()` method shows that the model is `ACTIVE` and the `predict()` method is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35467118",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa832c4",
   "metadata": {},
   "source": [
    "<a id='serialize_predict'></a>\n",
    "## Predict\n",
    "\n",
    "In the <a href='#create'>Create a Generic Model</a> section, you used the `model.predict()` method where `model` is an generic model object. This did inference using the local model. Now that the `GenericModel` model has been deployed, you can do the same thing using similar syntax with the `.predict()` method on a `GenericModel`. \n",
    "\n",
    "After the deployment is active, you can call the `predict()` on the `GenericModel` object to send request to the deployed endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.predict(X)[\"prediction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830755a8",
   "metadata": {},
   "source": [
    "<a id='clean_up'></a>\n",
    "# Clean Up\n",
    "\n",
    "This notebook created a model deployment and a model. This section deletes those resources. \n",
    "\n",
    "The model deployment must be deleted before the model can be deleted. You use the `.delete_deployment()` method on the `GenericModel` object to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = generic_model.delete_deployment(wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b921dd1",
   "metadata": {},
   "source": [
    "After the model deployment has been deleted, the `.summary_status()` method shows that the model has been deleted and that the `predict()` method is not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca42689",
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef1a4d9",
   "metadata": {},
   "source": [
    "Use the `.delete_model()` method in a `ModelCatalog` object to delete the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ecf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog(compartment_id=os.environ[\"NB_SESSION_COMPARTMENT_OCID\"]).delete_model(\n",
    "    model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67560f27",
   "metadata": {},
   "source": [
    "The next cell removes the model artifacts that were stored on your local drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a24575",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmtree(artifact_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c378ab79",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "- [ADS Library Documentation](https://accelerated-data-science.readthedocs.io/en/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Understanding Conda Environments](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/use-notebook-sessions.htm#conda_understand_environments)\n",
    "- [Use Resource Manager to Configure Your Tenancy for Data Science](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/orm-configure-tenancy.htm)\n",
    "- [`runtime.yaml`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_runtime_yaml.htm#model_runtime_yaml)\n",
    "- [`score.py`](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/model_score_py.htm#model_score_py)\n",
    "- [Model artifact](https://docs.content.oci.oracleiaas.com/en-us/iaas/data-science/using/models_saving_catalog.htm#create-models)\n",
    "- [ONNX API Summary](http://onnx.ai/sklearn-onnx/api_summary.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p38_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p38_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
